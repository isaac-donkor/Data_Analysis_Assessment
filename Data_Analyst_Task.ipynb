{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "792121ab",
   "metadata": {},
   "source": [
    "Using Selenium To Scrape Data of A Dynamic Website With JavaScript Enabled in chrome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c2c7184f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraped: 24 Daily Facial Cleansing Wipes Gentle 25 wipes^\n",
      "Scraped: 24 Daily Facial Cleansing Wipes Moisturising 25 wipes^\n",
      "Scraped: 24 Daily Pawpaw Ointment 25g^\n",
      "Scraped: A bit Hippy Cleanser 500ml^\n",
      "Scraped: A bit Hippy Conditioner 500ml^\n",
      "Scraped: A bit Hippy Face Cream 65g^\n",
      "Scraped: A bit Hippy Face Mist 100ml^\n",
      "Scraped: A bit Hippy Face Oil 25ml^\n",
      "Scraped: A bit Hippy Moisturiser 200g^\n",
      "Scraped: A bit Hippy Oil Cleanser 100ml^\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time\n",
    "import os\n",
    "import csv\n",
    "\n",
    "# Launch Chrome\n",
    "driver = webdriver.Chrome()\n",
    "driver.get(\"https://terrywhitechemmart.com.au/shop/products/skin-care\")\n",
    "\n",
    "wait = WebDriverWait(driver, 20)\n",
    "\n",
    "try:\n",
    "    # Wait for the product list container\n",
    "    product_list = wait.until(\n",
    "        EC.presence_of_element_located((By.CSS_SELECTOR, \"div.product-list\"))\n",
    "    )\n",
    "\n",
    "    # Find all product links\n",
    "    product_links = [\n",
    "        a.get_attribute(\"href\")\n",
    "        for a in product_list.find_elements(By.CSS_SELECTOR, \"mat-card.product-carousel-item-card a\")\n",
    "    ]\n",
    "\n",
    "    # Limit to first 10 products\n",
    "    product_links = product_links[:10]\n",
    "\n",
    "    # Prepare storage\n",
    "    all_products = []\n",
    "\n",
    "    # Loop through each product\n",
    "    for link in product_links:\n",
    "        driver.get(link)\n",
    "        time.sleep(2)  # short pause to ensure page loads\n",
    "\n",
    "        # Brand\n",
    "        try:\n",
    "            brand_div = wait.until(\n",
    "                EC.presence_of_element_located((By.CSS_SELECTOR, \"div[itemprop='brand'] meta[itemprop='name']\"))\n",
    "            )\n",
    "            brand_name = brand_div.get_attribute(\"content\")\n",
    "        except:\n",
    "            brand_name = None\n",
    "\n",
    "        # Product name\n",
    "        try:\n",
    "            product_elem = wait.until(\n",
    "                EC.presence_of_element_located((By.CSS_SELECTOR, \"h1\"))\n",
    "            )\n",
    "            product_name = product_elem.text\n",
    "        except:\n",
    "            product_name = None\n",
    "\n",
    "        # Description\n",
    "        try:\n",
    "            description_elem = wait.until(\n",
    "                EC.presence_of_element_located((By.CSS_SELECTOR, \"meta[itemprop='description']\"))\n",
    "            )\n",
    "            description = description_elem.get_attribute(\"content\")\n",
    "        except:\n",
    "            description = None\n",
    "\n",
    "        # Image URL\n",
    "        try:\n",
    "            image_elem = wait.until(\n",
    "                EC.presence_of_element_located((By.CSS_SELECTOR, \"link[itemprop='image']\"))\n",
    "            )\n",
    "            image_url = image_elem.get_attribute(\"href\")\n",
    "        except:\n",
    "            image_url = None\n",
    "\n",
    "        # Price\n",
    "        try:\n",
    "            price_meta = wait.until(\n",
    "                EC.presence_of_element_located((By.CSS_SELECTOR, \"meta[itemprop='price']\"))\n",
    "            )\n",
    "            price_value = price_meta.get_attribute(\"content\")\n",
    "        except:\n",
    "            price_value = None\n",
    "\n",
    "        # Ingredients\n",
    "        ingredients_text = None\n",
    "        try:\n",
    "            ingredients_panel = wait.until(\n",
    "                EC.element_to_be_clickable((By.XPATH, \"//mat-panel-title[contains(text(),'Ingredients')]\"))\n",
    "            )\n",
    "            ingredients_panel.click()\n",
    "            time.sleep(1)  # wait for panel to expand\n",
    "\n",
    "            ingredients_elems = wait.until(\n",
    "                EC.presence_of_all_elements_located((By.CSS_SELECTOR, \"div.mat-expansion-panel-body small.expand-panel-content\"))\n",
    "            )\n",
    "            if len(ingredients_elems) >= 4:\n",
    "                ingredients_text = ingredients_elems[3].text\n",
    "            elif len(ingredients_elems) > 0:\n",
    "                ingredients_text = ingredients_elems[0].text\n",
    "        except:\n",
    "            ingredients_text = None\n",
    "\n",
    "        # Store scraped data\n",
    "        product_data = {\n",
    "            \"Product_ID\": link, #Unique identifier from URL \n",
    "            \"Brand\": brand_name, #Brand of the product\n",
    "            \"Product Name\": product_name, #Brand of the product\n",
    "            \"Description\": description, #Brand of the product\n",
    "            \"Image URL\": image_url, #Direct image URLs\n",
    "            \"Price\": price_value, #Direct image URLs\n",
    "            \"Ingredients\": ingredients_text #Direct image URLs\n",
    "        }\n",
    "        all_products.append(product_data)\n",
    "\n",
    "        # Print progress\n",
    "        print(f\"Scraped: {product_name}\")\n",
    "\n",
    "    # After scraping all products, save to CSV\n",
    "    if all_products:\n",
    "        keys = all_products[0].keys()\n",
    "        file_exists = os.path.isfile(\"products.csv\")\n",
    "        with open(\"products.csv\", \"a\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "            writer = csv.DictWriter(f, fieldnames=keys)\n",
    "            if not file_exists:\n",
    "                writer.writeheader()\n",
    "            writer.writerows(all_products)\n",
    "\n",
    "finally:\n",
    "    driver.quit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1da0896",
   "metadata": {},
   "source": [
    "Clean And Group by Ingredients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "21232e01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grouped CSV saved as 'products_grouped_by_ingredients.csv'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the original CSV\n",
    "df = pd.read_csv(\"products.csv\")\n",
    "\n",
    "# Group by Ingredients and aggregate product details into lists\n",
    "grouped_df = df.groupby(\"Ingredients\").agg({\n",
    "    \"Product Name\": lambda x: \"; \".join(x),  # combine product names\n",
    "    \"Brand\": lambda x: \"; \".join(x),\n",
    "    \"Price\": lambda x: \"; \".join(x.astype(str)),\n",
    "    \"Description\": lambda x: \"; \".join(x.fillna(\"\")),  # handle any missing descriptions\n",
    "    \"Image URL\": lambda x: \"; \".join(x.fillna(\"\"))\n",
    "}).reset_index()\n",
    "\n",
    "# Save to a new CSV (does not overwrite the original)\n",
    "grouped_df.to_csv(\"products_grouped_by_ingredients.csv\", index=False, encoding=\"utf-8\")\n",
    "\n",
    "print(\"Grouped CSV saved as 'products_grouped_by_ingredients.csv'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "584d2a62",
   "metadata": {},
   "source": [
    "Finally, Group The Products Into Specified Format Per Assessment Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f21d5eae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grouped CSV saved as ' grouped ingredient table.csv'\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "\n",
    "# Read CSV\n",
    "df = pd.read_csv(\"products.csv\")\n",
    "\n",
    "# Group by Ingredients\n",
    "grouped = df.groupby(\"Ingredients\").agg({\n",
    "    \"Product Name\": lambda x: \", \".join(x)  # combine product names\n",
    "}).reset_index()\n",
    "\n",
    "# Assign group labels A, B, C ...\n",
    "letters = list(string.ascii_uppercase)\n",
    "grouped['Group'] = [letters[i] if i < len(letters) else f'Group_{i+1}' \n",
    "                    for i in range(len(grouped))]\n",
    "\n",
    "# Reorder columns: Group | Ingredients | Product Names\n",
    "grouped = grouped[['Group', 'Ingredients', 'Product Name']]\n",
    "\n",
    "# Save to new CSV\n",
    "grouped.to_csv(\"grouped ingredient table.csv\", index=False, encoding=\"utf-8\")\n",
    "\n",
    "print(\"Grouped CSV saved as 'grouped ingredient table.csv'\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
